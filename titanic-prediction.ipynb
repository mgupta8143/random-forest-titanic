{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-17T05:57:01.379450Z","iopub.execute_input":"2022-02-17T05:57:01.379987Z","iopub.status.idle":"2022-02-17T05:57:01.389374Z","shell.execute_reply.started":"2022-02-17T05:57:01.379953Z","shell.execute_reply":"2022-02-17T05:57:01.388755Z"},"trusted":true},"execution_count":358,"outputs":[]},{"cell_type":"markdown","source":"Note this is a pure classification task. There are many different options out there, as listed below:\n* Neural Networks (Cross-Entropy would work well here)\n* Clustering (KMeans, DBSCAN, Hierarchal, GMM, etc.)\n* Ensembles with SOTA\n* Etc, etc.\n\nFor this notebook, because I'm currently learning more about basic ML, I will try using a decision tree and evaluate performance. \n\nFirst, I'm going to analyze the data to see if there are any issues with it","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/titanic/train.csv\")\n\ndisplay(df.describe())\ndisplay(df.head())\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:57:01.450795Z","iopub.execute_input":"2022-02-17T05:57:01.451208Z","iopub.status.idle":"2022-02-17T05:57:01.498920Z","shell.execute_reply.started":"2022-02-17T05:57:01.451177Z","shell.execute_reply":"2022-02-17T05:57:01.497775Z"},"trusted":true},"execution_count":359,"outputs":[]},{"cell_type":"code","source":"num_vars = df.columns[df.dtypes != 'object']\ncat_vars = df.columns[df.dtypes == 'object']\n\nprint(num_vars)\nprint(cat_vars)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:57:01.500615Z","iopub.execute_input":"2022-02-17T05:57:01.500928Z","iopub.status.idle":"2022-02-17T05:57:01.508186Z","shell.execute_reply.started":"2022-02-17T05:57:01.500899Z","shell.execute_reply":"2022-02-17T05:57:01.507423Z"},"trusted":true},"execution_count":360,"outputs":[]},{"cell_type":"code","source":"df[num_vars].isnull().sum().sort_values(ascending=False)/len(df)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:57:01.509319Z","iopub.execute_input":"2022-02-17T05:57:01.509954Z","iopub.status.idle":"2022-02-17T05:57:01.525835Z","shell.execute_reply.started":"2022-02-17T05:57:01.509814Z","shell.execute_reply":"2022-02-17T05:57:01.524932Z"},"trusted":true},"execution_count":361,"outputs":[]},{"cell_type":"code","source":"df[cat_vars].isnull().sum().sort_values(ascending=False)/len(df)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:57:01.527066Z","iopub.execute_input":"2022-02-17T05:57:01.527308Z","iopub.status.idle":"2022-02-17T05:57:01.540339Z","shell.execute_reply.started":"2022-02-17T05:57:01.527268Z","shell.execute_reply":"2022-02-17T05:57:01.539511Z"},"trusted":true},"execution_count":362,"outputs":[]},{"cell_type":"markdown","source":"Evidently, we can see that most of the data is present, however for the cabin, column, a lot of data is not there, hence we will remove it. For age, we will not as 80% of the rows will, and for now we will settle with filling the remaining 20% with the mean of the existing values. For embarked, we will just fill the remaining with the most column letter.","metadata":{}},{"cell_type":"code","source":"df[num_vars] = df[num_vars].apply(lambda col: col.fillna(col.mean()))\ndf = df.drop(columns=['Cabin', 'PassengerId'])\nnum_vars = df.columns[df.dtypes != 'object']\ncat_vars = df.columns[df.dtypes == 'object']\ndf[cat_vars] = df[cat_vars].apply(lambda col: col.fillna(col.mode()[0]))\n\ndisplay(df[num_vars].isnull().sum().sort_values(ascending=False)/len(df))\ndisplay(df[cat_vars].isnull().sum().sort_values(ascending=False)/len(df))\n\nsex = pd.get_dummies(df['Sex'], drop_first=True)\nembark = pd.get_dummies(df['Embarked'], drop_first=True)\npclass = pd.get_dummies(df['Pclass'], drop_first=True)\n\n\ndf = pd.concat([df, sex, embark, pclass], axis=1)\ndf.drop(['Sex', 'Embarked', 'Pclass', \"Ticket\", \"Name\"], axis=1, inplace=True)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:57:01.542438Z","iopub.execute_input":"2022-02-17T05:57:01.543315Z","iopub.status.idle":"2022-02-17T05:57:01.595913Z","shell.execute_reply.started":"2022-02-17T05:57:01.543272Z","shell.execute_reply":"2022-02-17T05:57:01.595011Z"},"trusted":true},"execution_count":363,"outputs":[]},{"cell_type":"markdown","source":"Now that the data has been cleaned, we can start using our decision tree classifier.","metadata":{}},{"cell_type":"code","source":"dataset = df.to_numpy()\nprint(dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:57:01.598384Z","iopub.execute_input":"2022-02-17T05:57:01.598633Z","iopub.status.idle":"2022-02-17T05:57:01.603672Z","shell.execute_reply.started":"2022-02-17T05:57:01.598605Z","shell.execute_reply":"2022-02-17T05:57:01.602615Z"},"trusted":true},"execution_count":364,"outputs":[]},{"cell_type":"code","source":"X = dataset[:, 1:]\nY = dataset[:, 0]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:57:01.605018Z","iopub.execute_input":"2022-02-17T05:57:01.605233Z","iopub.status.idle":"2022-02-17T05:57:01.617998Z","shell.execute_reply.started":"2022-02-17T05:57:01.605207Z","shell.execute_reply":"2022-02-17T05:57:01.617022Z"},"trusted":true},"execution_count":365,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cluster import MiniBatchKMeans\n\nclf = RandomForestClassifier()\nclf = clf.fit(X, Y)\n\ntest_df = pd.read_csv(\"../input/titanic/test.csv\")\ntest_df = test_df.drop(columns=['Cabin', 'PassengerId'])\nnum_vars = test_df.columns[test_df.dtypes != 'object']\ncat_vars = test_df.columns[test_df.dtypes == 'object']\ntest_df[num_vars] = test_df[num_vars].apply(lambda col: col.fillna(col.mean()))\ndisplay(test_df[num_vars].isnull().sum().sort_values(ascending=False)/len(df))\ndisplay(test_df[cat_vars].isnull().sum().sort_values(ascending=False)/len(df))\n\nsex = pd.get_dummies(test_df['Sex'], drop_first=True)\nembark = pd.get_dummies(test_df['Embarked'], drop_first=True)\npclass = pd.get_dummies(test_df['Pclass'], drop_first=True)\n\ntest_df = pd.concat([test_df, sex, embark, pclass], axis=1)\ntest_df.drop(['Sex', 'Embarked', 'Pclass', \"Ticket\", \"Name\"], axis=1, inplace=True)\ndisplay(test_df.head())\n\n\ntest_X = test_df.to_numpy()\npredictions = clf.predict(test_X)\n\ninter = []\ncount = 892\nfor i in range(len(predictions)):\n    inter.append([count, int(predictions[i])])\n    count += 1\n\noutput = pd.DataFrame(inter, columns=[\"PassengerId\", \"Survived\"])\noutput.to_csv('predictions_fixed.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:57:01.619686Z","iopub.execute_input":"2022-02-17T05:57:01.620313Z","iopub.status.idle":"2022-02-17T05:57:01.946166Z","shell.execute_reply.started":"2022-02-17T05:57:01.620263Z","shell.execute_reply":"2022-02-17T05:57:01.945158Z"},"trusted":true},"execution_count":366,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}